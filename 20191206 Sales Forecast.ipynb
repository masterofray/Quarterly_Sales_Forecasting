{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dtz\n",
    "from sklearn.preprocessing import Normalizer,LabelEncoder\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Density\n",
    "from scipy.stats import gamma\n",
    "\n",
    "# Machine learning toolkit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\n",
    "\n",
    "# Cross Validation(k-fold)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Make pandas display in scientific format for all continuous computing\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "\n",
    "# Set panda option to display row and columns\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last date we try to compile this code at : 2019-12-06 14:01:02.008624\n"
     ]
    }
   ],
   "source": [
    "Compile_date = dtz.datetime.now()\n",
    "print('The last date we try to compile this code at :',Compile_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We input the Sales Data\n",
      "________________________________________________________________________________\n",
      "Number of Sales Data's Column is 5\n",
      "Number of Sales Data's Row is 102239\n",
      "Name of Sales Data's Columns are :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No           int64\n",
       "Period      object\n",
       "AC         float64\n",
       "Zone        object\n",
       "Monthly    float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('We input the Sales Data')\n",
    "SBU = pd.read_csv('./DATA/RAW.csv', delimiter = ';')\n",
    "print('_'*80)\n",
    "\n",
    "#Shape of SBU Data\n",
    "print(\"Number of Sales Data's Column is\",SBU.shape[1])\n",
    "print(\"Number of Sales Data's Row is\",SBU.shape[0])\n",
    "#Print Column Name\n",
    "print(\"Name of Sales Data's Columns are :\")\n",
    "display(SBU.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>AC</th>\n",
       "      <th>Zone</th>\n",
       "      <th>Monthly</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>1011000000000</td>\n",
       "      <td>Zone 01</td>\n",
       "      <td>1284294</td>\n",
       "      <td>01</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-01</th>\n",
       "      <td>2</td>\n",
       "      <td>1011000000000</td>\n",
       "      <td>Zone 01</td>\n",
       "      <td>1639863</td>\n",
       "      <td>02</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01</th>\n",
       "      <td>3</td>\n",
       "      <td>1011000000000</td>\n",
       "      <td>Zone 01</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            No            AC     Zone  Monthly Month  Year\n",
       "Date                                                      \n",
       "2016-01-01   1 1011000000000  Zone 01  1284294    01  2016\n",
       "2016-02-01   2 1011000000000  Zone 01  1639863    02  2016\n",
       "2016-03-01   3 1011000000000  Zone 01        1    03  2016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Customize the Date attribute\n",
    "from datetime import datetime\n",
    "\n",
    "def att_time(df, att, dlt) :\n",
    "    new = df[att].str.split(dlt, n = 1, expand = True) #we split the period attribute into 2 columns by the space\n",
    "    #display(new.head(3))\n",
    "    df['Month'] = new[1]\n",
    "    df['Year'] = new[0]\n",
    "    #display(df.head(3)) # We got 2 columns with the month and year\n",
    "\n",
    "    s1 = df['Month'].tolist()\n",
    "    s2 = df['Year'].tolist()\n",
    "\n",
    "    s3 = [] #make a container for date parsing\n",
    "    for i in range(len(s1)) :\n",
    "        s4 = '{}-{}-01'.format(s2[i], s1[i])\n",
    "        s4 = datetime.strptime(s4,'%Y-%m-%d').date() #make it type date by parse the date format in string type\n",
    "        s3.append(s4) #add the result into s3 list\n",
    "    \n",
    "    df['Date'] = s3 #make it part of Data attribute\n",
    "    df.drop([att], axis = 1, inplace=True) #try to remove att attribute in data\n",
    "    df.set_index('Date',inplace=True) #Set date attribute as the index\n",
    "    #df.reset_index(inplace=True)\n",
    "    display(df.head(3))\n",
    "    \n",
    "att_time(SBU, att='Period', dlt=' ')\n",
    "SBU.rename(columns={'Monthly':'Num_Sales'}, inplace=True)\n",
    "SBU.drop(['No'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the describe for data continuous :\n",
      "\n",
      "                 AC  Num_Sales\n",
      "count        102239     102239\n",
      "mean  1011326307378    5724675\n",
      "std       270408538   61125496\n",
      "min   1011000000000          0\n",
      "25%   1011010000000          0\n",
      "50%   1011400000000          1\n",
      "75%   1011600000000     472468\n",
      "max   1012000000000 4695129768\n",
      "________________________________________________________________________________\n",
      "\n",
      "This is the describe for data Object :\n",
      "\n",
      "            Zone   Month    Year\n",
      "count     102239  102239  102239\n",
      "unique        12      12       4\n",
      "top     National      12    2019\n",
      "freq       15482    8938   28904\n",
      "________________________________________________________________________________\n",
      "\n",
      "This is head of data :\n",
      "\n",
      "                      AC     Zone  Num_Sales Month  Year\n",
      "Date                                                    \n",
      "2016-01-01 1011000000000  Zone 01    1284294    01  2016\n",
      "2016-02-01 1011000000000  Zone 01    1639863    02  2016\n",
      "2016-03-01 1011000000000  Zone 01          1    03  2016\n",
      "2016-04-01 1011000000000  Zone 01    1995432    04  2016\n",
      "________________________________________________________________________________\n",
      "\n",
      "This is type of data in each columns :\n",
      "\n",
      "AC           float64\n",
      "Zone          object\n",
      "Num_Sales    float64\n",
      "Month         object\n",
      "Year          object\n",
      "dtype: object\n",
      "________________________________________________________________________________\n",
      "\n",
      "This is number of NaN in data :\n",
      "\n",
      "AC           0\n",
      "Zone         0\n",
      "Num_Sales    0\n",
      "Month        0\n",
      "Year         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def overview(df) :\n",
    "    print('This is the describe for data continuous :\\n')\n",
    "    print(df.describe())\n",
    "    print('_'*80+'\\n')\n",
    "    print('This is the describe for data Object :\\n')\n",
    "    print(df.describe(include='O'))\n",
    "    print('_'*80+'\\n')\n",
    "    print('This is head of data :\\n')\n",
    "    print(df.head(4))\n",
    "    print('_'*80+'\\n')\n",
    "    print('This is type of data in each columns :\\n')\n",
    "    print(df.dtypes)\n",
    "    print('_'*80+'\\n')    \n",
    "    print('This is number of NaN in data :\\n')\n",
    "    print(df.isna().sum())\n",
    "\n",
    "overview(SBU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>Zone</th>\n",
       "      <th>Num_Sales</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>1011000000000</td>\n",
       "      <td>Zone 01</td>\n",
       "      <td>1284294</td>\n",
       "      <td>01</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-01</th>\n",
       "      <td>1011000000000</td>\n",
       "      <td>Zone 01</td>\n",
       "      <td>1639863</td>\n",
       "      <td>02</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01</th>\n",
       "      <td>1011000000000</td>\n",
       "      <td>Zone 01</td>\n",
       "      <td>1</td>\n",
       "      <td>03</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      AC     Zone  Num_Sales Month  Year\n",
       "Date                                                    \n",
       "2016-01-01 1011000000000  Zone 01    1284294    01  2016\n",
       "2016-02-01 1011000000000  Zone 01    1639863    02  2016\n",
       "2016-03-01 1011000000000  Zone 01          1    03  2016"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (15,12))\n",
    "SBUstr = SBU.select_dtypes(include=['object'])\n",
    "strSBU = SBUstr.columns.values.tolist()[40:50]\n",
    "for i, feature in enumerate(strSBU):\n",
    "    ax = fig.add_subplot(5, 2, i+1)\n",
    "    SBU.groupby('Zone')[feature].count().plot(kind='bar', color = '#00A0A0')\n",
    "    ax.set_title('%s'%(feature), fontsize = 14)\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "SBU.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC            object\n",
      "Zone          object\n",
      "Num_Sales    float64\n",
      "Month         object\n",
      "Year          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "converty = {'AC' : 'str',\n",
    "           'Zone' : 'str',\n",
    "           'Num_Sales' : 'float',\n",
    "           'Month' : 'str',\n",
    "           'Year' : 'str'}\n",
    "SBU_X = SBU.astype(converty) \n",
    "print(SBU_X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBU_X = SBU_X[(SBU_X['Zone']== 'National')].sort_index()\n",
    "SBU_X.drop(['Zone'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     6327\n",
       "1     2387\n",
       "6     2289\n",
       "3     1281\n",
       "8     1026\n",
       "9      839\n",
       "2      478\n",
       "4      440\n",
       "5      226\n",
       "10     135\n",
       "11      30\n",
       "12      24\n",
       "Name: AC, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBU_X['AC'] = SBU_X['AC'].map({\n",
    "'1011000000000.0' : 1,\n",
    "'1011010000000.0' : 2,\n",
    "'1011100000000.0' : 3,\n",
    "'1011200000000.0' : 4,\n",
    "'1011300000000.0' : 5,\n",
    "'1011400000000.0' : 6,\n",
    "'1011600000000.0' : 7,\n",
    "'1011700000000.0' : 8,\n",
    "'1011810000000.0' : 9,\n",
    "'1011500000000.0' : 10,\n",
    "'1011900000000.0' : 11,\n",
    "'1012000000000.0' : 12\n",
    "}).astype(int)\n",
    "SBU_X['AC'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SBU_X['Zone'] = SBU_X['Zone'].map({\n",
    "'Zone 01' : 1,\n",
    "'Zone 02A' : 2,\n",
    "'Zone 02B' : 3,\n",
    "'Zone 03' : 4,\n",
    "'Zone 04' : 5,\n",
    "'Zone 05' : 6,\n",
    "'Zone 06' : 7,\n",
    "'Zone 07' : 8,\n",
    "'Zone 08' : 9,\n",
    "'Zone 02 AFH' : 10,\n",
    "'Zone 09' : 11,\n",
    "'National' : 12\n",
    "}).astype(int)\n",
    "SBU_X['Zone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    1337\n",
       "11    1330\n",
       "10    1329\n",
       "9     1320\n",
       "8     1306\n",
       "7     1293\n",
       "6     1287\n",
       "5     1274\n",
       "4     1269\n",
       "3     1255\n",
       "2     1245\n",
       "1     1237\n",
       "Name: Month, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBU_X['Month'] = SBU_X['Month'].map({\n",
    "'01' : 1,\n",
    "'02' : 2,\n",
    "'03' : 3,\n",
    "'04' : 4,\n",
    "'05' : 5,\n",
    "'06' : 6,\n",
    "'07' : 7,\n",
    "'08' : 8,\n",
    "'09' : 9,\n",
    "'10' : 10,\n",
    "'11' : 11,\n",
    "'12' : 12\n",
    "}).astype(int)\n",
    "SBU_X['Month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    4268\n",
       "3    4090\n",
       "2    3793\n",
       "1    3331\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBU_X['Year'] = SBU_X['Year'].map({\n",
    "'2016' : 1,\n",
    "'2017' : 2,\n",
    "'2018' : 3,\n",
    "'2019' : 4\n",
    "}).astype(int)\n",
    "SBU_X['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Initial Setting Array from Dataframe\n",
    "Yrfe = SBU_X['Num_Sales'].values.copy()\n",
    "SBU_X2 = SBU_X.drop(['Num_Sales'], axis = 1).copy()\n",
    "Xrfe = SBU_X2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = SBU_X[['Num_Sales', 'AC', 'Month', 'Year']].corr()\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Model\n",
    "for Supervised Learning plus Classification and Regression, our choice of models to are:\n",
    "\n",
    "- Logistic Regression\n",
    "- KNN or k-Nearest Neighbors\n",
    "- Support Vector Machines\n",
    "- Naive Bayes classifier\n",
    "- Decision Tree\n",
    "- Random Forrest\n",
    "- Perceptron\n",
    "- Artificial neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Yxx = pd.cut(Y,10)\n",
    "#Yxx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Trainning Data of Features : (9289, 3)\n",
      "Dimension of Test Data of Features : (6193, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = SBU_X['Num_Sales'].copy()\n",
    "X = SBU_X.drop(['Num_Sales'], axis = 1).copy()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1, test_size = 0.4)\n",
    "Y_train = Y_train.astype('int').copy()\n",
    "Y_test = Y_test.astype('int').copy()\n",
    "\n",
    "features_train = X_train.copy()\n",
    "label_train = Y_train.copy()\n",
    "features_test = X_test.copy()\n",
    "label_test = Y_test.copy()\n",
    "\n",
    "print('Dimension of Trainning Data of Features : {}'.format(X_train.shape))\n",
    "print('Dimension of Test Data of Features : {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(ytests,ypredicts) :\n",
    "    ytlist = ytests.to_list()\n",
    "    yplist = ypredicts.tolist()\n",
    "    holdz = []\n",
    "    for i in range(len(ytlist)):\n",
    "        temp = (ytlist[i] - yplist[i])**2\n",
    "        holdz.append(temp)\n",
    "    mses = sum(holdz)/len(ytlist)\n",
    "    Variance = np.var(ypredicts)\n",
    "    Biases = np.sqrt(mses - Variance)\n",
    "    sentence = 'The MSE is {:0.3f} \\nThe Variance is {:0.3f} \\nThe Biased is {:0.3f}'\n",
    "    print(sentence.format(mses, Variance, Biases))\n",
    "    return [mses, Variance, Biases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data = 40.88 %.\n",
      "Accuracy of Test Data = 40.16 %.\n",
      "AUC coeficient of Train Data = 56.54 %.\n",
      "AUC coeficient of Test Data = 66.09 %.\n",
      "Accuracy of Training X and Y Data = 40.88 %.\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression(solver='lbfgs')\n",
    "#logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train,Y_train)\n",
    "\n",
    "pred_train = logreg.predict(X_train)\n",
    "pred_test = logreg.predict(X_test)\n",
    "pred_logistic = pred_test.copy()\n",
    "\n",
    "accuracy_train = accuracy_score(pred_train,Y_train)\n",
    "accuracy_test = accuracy_score(pred_test,Y_test)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "\n",
    "#Auc = Area under Curve\n",
    "#Roc = Receiver Operating Characteristics\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train),logreg.predict_proba(X_train)[:,1],pos_label=1)\n",
    "auc_train = metrics.auc(fpr,tpr)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test),logreg.predict_proba(X_test)[:,1],pos_label=1)\n",
    "auc_test = metrics.auc(fpr,tpr)\n",
    "\n",
    "acc_log2 = round(accuracy_train*100,2)\n",
    "print('Accuracy of Train Data =',acc_log2,'%.')\n",
    "print('Accuracy of Test Data =',round(accuracy_test*100,2),'%.')\n",
    "print('AUC coeficient of Train Data =',round(auc_train*100,2),'%.')\n",
    "print('AUC coeficient of Test Data =',round(auc_test*100,2),'%.')\n",
    "print('Accuracy of Training X and Y Data =',acc_log,'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix test for logistic regression\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,   16,    0, ...,    0,    0,    0],\n",
       "       [   0, 3797,    0, ...,    0,    0,    0],\n",
       "       [   0,   24,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Tabulation for test data in logistic regression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "\n",
      "Confusion Matrix test for logistic regression\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    6,    0, ...,    0,    0,    0],\n",
       "       [   0, 2487,    0, ...,    0,    0,    0],\n",
       "       [   0,   22,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Tabulation for test data in logistic regression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('Confusion Matrix test for logistic regression')\n",
    "Conf_Logtrain = confusion_matrix(Y_train, pred_train)\n",
    "display(Conf_Logtrain)\n",
    "print('Cross Tabulation for test data in logistic regression')\n",
    "display(pd.crosstab(Y_train,pd.Series(pred_train),rownames=['ACTUAL'],colnames=['PRED']))\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Confusion Matrix test for logistic regression')\n",
    "Y_tests = Y_test.astype('int')\n",
    "Conf_Logtest = confusion_matrix(Y_tests, pred_test)\n",
    "display(Conf_Logtest)\n",
    "print('Cross Tabulation for test data in logistic regression')\n",
    "display(pd.crosstab(Y_tests,pd.Series(pred_test),rownames=['ACTUAL'],colnames=['PRED']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance and Biased for Train Prediction\n",
      "The MSE is 15430283936876096.000 \n",
      "The Variance is 0.000 \n",
      "The Biased is 124218693.991\n",
      "______________________________________________________________________\n",
      "\n",
      "Variance and Biased for Test Prediction\n",
      "The MSE is 12057285451630762.000 \n",
      "The Variance is 0.000 \n",
      "The Biased is 109805671.309\n"
     ]
    }
   ],
   "source": [
    "print('Variance and Biased for Train Prediction')\n",
    "MSE(Y_train,pred_train)\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Variance and Biased for Test Prediction')\n",
    "MSE_LOG = MSE(Y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Year</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Month</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC</td>\n",
       "      <td>-1.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature  Correlation\n",
       "2    Year         0.37\n",
       "1   Month         0.01\n",
       "0      AC        -1.55"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "coeff_df = pd.DataFrame(X_train.columns)\n",
    "coeff_df.columns = ['Feature']\n",
    "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "coeff_df.sort_values(by='Correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data = 41.47 %.\n",
      "Accuracy of Test Data = 38.41 %.\n",
      "AUC coeficient of Train Data = 54.85 %.\n",
      "AUC coeficient of Test Data = 58.79 %.\n"
     ]
    }
   ],
   "source": [
    "RFc = RandomForestClassifier()\n",
    "RFc.fit(X_train,Y_train)\n",
    "\n",
    "pred_trainRF = RFc.predict(X_train)\n",
    "pred_testRF = RFc.predict(X_test)\n",
    "\n",
    "accuracy_trainRF = accuracy_score(pred_trainRF,Y_train)\n",
    "accuracy_testRF = accuracy_score(pred_testRF,Y_test)\n",
    "\n",
    "#Auc = Area under Curve\n",
    "#Roc = Receiver Operating Characteristics\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train),RFc.predict_proba(X_train)[:,1],pos_label=1)\n",
    "auc_trainRF = metrics.auc(fpr,tpr)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test),RFc.predict_proba(X_test)[:,1],pos_label=1)\n",
    "auc_testRF = metrics.auc(fpr,tpr)\n",
    "\n",
    "acc_RF = round(accuracy_trainRF*100,2)\n",
    "print('Accuracy of Train Data =',acc_RF,'%.')\n",
    "print('Accuracy of Test Data =',round(accuracy_testRF*100,2),'%.')\n",
    "print('AUC coeficient of Train Data =',round(auc_trainRF*100,2),'%.')\n",
    "print('AUC coeficient of Test Data =',round(auc_testRF*100,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix test for Random Forest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,   16,    0, ...,    0,    0,    0],\n",
       "       [   0, 3746,    0, ...,    0,    0,    0],\n",
       "       [   0,   24,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Tabulation for test data in Random Forest\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "\n",
      "Confusion Matrix test for Random Forest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    6,    0, ...,    0,    0,    0],\n",
       "       [   0, 2379,    0, ...,    0,    0,    0],\n",
       "       [   0,   21,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Tabulation for test data in Random Forest\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Confusion Matrix test for Random Forest')\n",
    "display(confusion_matrix(Y_train, pred_trainRF))\n",
    "print('Cross Tabulation for test data in Random Forest')\n",
    "display(pd.crosstab(Y_train,pd.Series(pred_trainRF),rownames=['ACTUAL'],colnames=['PRED']))\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Confusion Matrix test for Random Forest')\n",
    "display(confusion_matrix(Y_test, pred_testRF))\n",
    "print('Cross Tabulation for test data in Random Forest')\n",
    "display(pd.crosstab(Y_test,pd.Series(pred_testRF),rownames=['ACTUAL'],colnames=['PRED']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance and Biased for Train Prediction\n",
      "The MSE is 16761240775637402.000 \n",
      "The Variance is 2278355611598262.500 \n",
      "The Biased is 120344859.317\n",
      "______________________________________________________________________\n",
      "\n",
      "Variance and Biased for Test Prediction\n",
      "The MSE is 14135609105879394.000 \n",
      "The Variance is 2605070605890684.500 \n",
      "The Biased is 107380345.036\n"
     ]
    }
   ],
   "source": [
    "print('Variance and Biased for Train Prediction')\n",
    "MSE(Y_train,pred_trainRF)\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Variance and Biased for Test Prediction')\n",
    "MSE_RF = MSE(Y_test,pred_testRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data = 41.08 %.\n",
      "Accuracy of Test Data = 39.27 %.\n",
      "AUC coeficient of Train Data = 59.02 %.\n",
      "AUC coeficient of Test Data = 59.7 %.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "NNc = MLPClassifier()\n",
    "\n",
    "NNc.fit(X_train,Y_train)\n",
    "\n",
    "pred_trainNN = NNc.predict(X_train)\n",
    "pred_testNN = NNc.predict(X_test)\n",
    "\n",
    "accuracy_trainNN = accuracy_score(pred_trainNN,Y_train)\n",
    "accuracy_testNN = accuracy_score(pred_testNN,Y_test)\n",
    "\n",
    "#Auc = Area under Curve\n",
    "#Roc = Receiver Operating Characteristics\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train),NNc.predict_proba(X_train)[:,1],pos_label=1)\n",
    "auc_trainNN = metrics.auc(fpr,tpr)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test),NNc.predict_proba(X_test)[:,1],pos_label=1)\n",
    "auc_testNN = metrics.auc(fpr,tpr)\n",
    "\n",
    "acc_NN = round(accuracy_trainNN*100,2)\n",
    "print('Accuracy of Train Data =',acc_NN,'%.')\n",
    "print('Accuracy of Test Data =',round(accuracy_testNN*100,2),'%.')\n",
    "print('AUC coeficient of Train Data =',round(auc_trainNN*100,2),'%.')\n",
    "print('AUC coeficient of Test Data =',round(auc_testNN*100,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix test for Neural Network\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,   16,    0, ...,    0,    0,    0],\n",
       "       [   0, 3729,    0, ...,    0,    0,    0],\n",
       "       [   0,   24,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Tabulation for test data in Neural Network\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "\n",
      "Confusion Matrix test for Neural Network\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    6,    0, ...,    0,    0,    0],\n",
       "       [   0, 2432,    0, ...,    0,    0,    0],\n",
       "       [   0,   22,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0],\n",
       "       [   0,    1,    0, ...,    0,    0,    0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Tabulation for test data in Neural Network\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Confusion Matrix test for Neural Network')\n",
    "display(confusion_matrix(Y_train, pred_trainNN))\n",
    "print('Cross Tabulation for test data in Neural Network')\n",
    "display(pd.crosstab(Y_train,pd.Series(pred_trainNN),rownames=['ACTUAL'],colnames=['PRED']))\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Confusion Matrix test for Neural Network')\n",
    "display(confusion_matrix(Y_test, pred_testNN))\n",
    "print('Cross Tabulation for test data in Neural Network')\n",
    "display(pd.crosstab(Y_test,pd.Series(pred_testNN),rownames=['ACTUAL'],colnames=['PRED']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance and Biased for Train Prediction\n",
      "The MSE is 16130946681906846.000 \n",
      "The Variance is 1287925758161655.500 \n",
      "The Biased is 121831937.208\n",
      "______________________________________________________________________\n",
      "\n",
      "Variance and Biased for Test Prediction\n",
      "The MSE is 13443681294503460.000 \n",
      "The Variance is 1592093816006711.250 \n",
      "The Biased is 108864996.571\n"
     ]
    }
   ],
   "source": [
    "print('Variance and Biased for Train Prediction')\n",
    "MSE(Y_train,pred_trainNN)\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Variance and Biased for Test Prediction')\n",
    "MSE_NN = MSE(Y_test,pred_testNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train Data = 6.59 %.\n",
      "Accuracy of Test Data = 2.55 %.\n",
      "AUC coeficient of Train Data = 43.71 %.\n",
      "AUC coeficient of Test Data = 48.17 %.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "NByc = GaussianNB()\n",
    "\n",
    "NByc.fit(X_train,Y_train)\n",
    "\n",
    "pred_trainNBy = NByc.predict(X_train)\n",
    "pred_testNBy = NByc.predict(X_test)\n",
    "\n",
    "accuracy_trainNBy = accuracy_score(pred_trainNBy,Y_train)\n",
    "accuracy_testNBy = accuracy_score(pred_testNBy,Y_test)\n",
    "\n",
    "#Auc = Area under Curve\n",
    "#Roc = Receiver Operating Characteristics\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train),NByc.predict_proba(X_train)[:,1],pos_label=1)\n",
    "auc_trainNBy = metrics.auc(fpr,tpr)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test),NByc.predict_proba(X_test)[:,1],pos_label=1)\n",
    "auc_testNBy = metrics.auc(fpr,tpr)\n",
    "\n",
    "acc_NBy = round(accuracy_trainNBy*100,2)\n",
    "print('Accuracy of Train Data =',acc_NBy,'%.')\n",
    "print('Accuracy of Test Data =',round(accuracy_testNBy*100,2),'%.')\n",
    "print('AUC coeficient of Train Data =',round(auc_trainNBy*100,2),'%.')\n",
    "print('AUC coeficient of Test Data =',round(auc_testNBy*100,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix test for Naive Bayes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "       [ 94, 240,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Tabulation for test data in Naive Bayes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________\n",
      "\n",
      "Confusion Matrix test for Naive Bayes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "       [ 71, 158,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,   0,   0, ...,   0,   0,   0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Tabulation for test data in Naive Bayes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Confusion Matrix test for Naive Bayes')\n",
    "display(confusion_matrix(Y_train, pred_trainNBy))\n",
    "print('Cross Tabulation for test data in Naive Bayes')\n",
    "display(pd.crosstab(Y_train,pd.Series(pred_trainNBy),rownames=['ACTUAL'],colnames=['PRED']))\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Confusion Matrix test for Naive Bayes')\n",
    "display(confusion_matrix(Y_test, pred_testNBy))\n",
    "print('Cross Tabulation for test data in Naive Bayes')\n",
    "display(pd.crosstab(Y_test,pd.Series(pred_testNBy),rownames=['ACTUAL'],colnames=['PRED']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance and Biased for Train Prediction\n",
      "The MSE is 62092652007708184.000 \n",
      "The Variance is 46222321393514816.000 \n",
      "The Biased is 125977500.428\n",
      "______________________________________________________________________\n",
      "\n",
      "Variance and Biased for Test Prediction\n",
      "The MSE is 64932475486655152.000 \n",
      "The Variance is 52300074933041416.000 \n",
      "The Biased is 112393952.478\n"
     ]
    }
   ],
   "source": [
    "print('Variance and Biased for Train Prediction')\n",
    "MSE(Y_train,pred_trainNBy)\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Variance and Biased for Test Prediction')\n",
    "MSE_NBy = MSE(Y_test,pred_testNBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-9d5ff0a445b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mGBc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mGBc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpred_trainGB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGBc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1544\u001b[0m         n_stages = self._fit_stages(\n\u001b[0;32m   1545\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1546\u001b[1;33m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1608\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[0;32m   1609\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m             residual = loss.negative_gradient(y, raw_predictions_copy, k=k,\n\u001b[1;32m-> 1221\u001b[1;33m                                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[1;31m# induce regression tree on residuals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py\u001b[0m in \u001b[0;36mnegative_gradient\u001b[1;34m(self, y, raw_predictions, k, **kwargs)\u001b[0m\n\u001b[0;32m    736\u001b[0m         \"\"\"\n\u001b[0;32m    737\u001b[0m         return y - np.nan_to_num(np.exp(raw_predictions[:, k] -\n\u001b[1;32m--> 738\u001b[1;33m                                         logsumexp(raw_predictions, axis=1)))\n\u001b[0m\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m     def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\special\\_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[1;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ma_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;31m# suppress warnings about log of zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBc = GradientBoostingClassifier()\n",
    "\n",
    "GBc.fit(X_train,Y_train)\n",
    "\n",
    "pred_trainGB = GBc.predict(X_train)\n",
    "pred_testGB = GBc.predict(X_test)\n",
    "\n",
    "accuracy_trainGB = accuracy_score(pred_trainGB,Y_train)\n",
    "accuracy_testGB = accuracy_score(pred_testGB,Y_test)\n",
    "\n",
    "#Auc = Area under Curve\n",
    "#Roc = Receiver Operating Characteristics\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train),GBc.predict_proba(X_train)[:,1],pos_label=1)\n",
    "auc_trainGB = metrics.auc(fpr,tpr)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test),GBc.predict_proba(X_test)[:,1],pos_label=1)\n",
    "auc_testGB = metrics.auc(fpr,tpr)\n",
    "\n",
    "acc_GB = round(accuracy_trainGB*100,2)\n",
    "print('Accuracy of Train Data =',acc_GB,'%.')\n",
    "print('Accuracy of Test Data =',round(accuracy_testGB*100,2),'%.')\n",
    "print('AUC coeficient of Train Data =',round(auc_trainGB*100,2),'%.')\n",
    "print('AUC coeficient of Test Data =',round(auc_testGB*100,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix test for Gradient Boosting')\n",
    "display(confusion_matrix(Y_train, pred_trainGB))\n",
    "print('Cross Tabulation for test data in Gradient Boosting')\n",
    "display(pd.crosstab(Y_train,pd.Series(pred_trainGB),rownames=['ACTUAL'],colnames=['PRED']))\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Confusion Matrix test for Gradient Boosting')\n",
    "display(confusion_matrix(Y_test, pred_testGB))\n",
    "print('Cross Tabulation for test data in Gradient Boosting')\n",
    "display(pd.crosstab(Y_test,pd.Series(pred_testGB),rownames=['ACTUAL'],colnames=['PRED']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variance and Biased for Train Prediction')\n",
    "MSE(Y_train,pred_trainGB)\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Variance and Biased for Test Prediction')\n",
    "MSE_GB = MSE(Y_test,pred_testGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train,Y_train)\n",
    "\n",
    "pred_trainSVC = svc.predict(X_train)\n",
    "pred_testSVC = svc.predict(X_test)\n",
    "\n",
    "accuracy_trainSVC = accuracy_score(pred_trainSVC,Y_train)\n",
    "accuracy_testSVC = accuracy_score(pred_testSVC,Y_test)\n",
    "\n",
    "acc_SVC = round(accuracy_trainSVC*100,2)\n",
    "print('Accuracy of Train Data =',acc_SVC,'%.')\n",
    "print('Accuracy of Test Data =',round(accuracy_testSVC*100,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix test for Support Vector Machine')\n",
    "display(confusion_matrix(Y_train, pred_trainSVC))\n",
    "print('Cross Tabulation for test data in Support Vector Machine')\n",
    "display(pd.crosstab(Y_train,pd.Series(pred_trainSVC),rownames=['ACTUAL'],colnames=['PRED']))\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Confusion Matrix test for Support Vector Machine')\n",
    "display(confusion_matrix(Y_test, pred_testSVC))\n",
    "print('Cross Tabulation for test data in Support Vector Machine')\n",
    "display(pd.crosstab(Y_test,pd.Series(pred_testSVC),rownames=['ACTUAL'],colnames=['PRED']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variance and Biased for Train Prediction')\n",
    "MSE(Y_train,pred_trainSVC)\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Variance and Biased for Test Prediction')\n",
    "MSE_SVC = MSE(Y_test,pred_testSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTc = DecisionTreeClassifier()\n",
    "\n",
    "DTc.fit(X_train,Y_train)\n",
    "\n",
    "pred_trainDT = DTc.predict(X_train)\n",
    "pred_testDT = DTc.predict(X_test)\n",
    "\n",
    "accuracy_trainDT = accuracy_score(pred_trainDT,Y_train)\n",
    "accuracy_testDT = accuracy_score(pred_testDT,Y_test)\n",
    "\n",
    "#Auc = Area under Curve\n",
    "#Roc = Receiver Operating Characteristics\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train),DTc.predict_proba(X_train)[:,1],pos_label=1)\n",
    "auc_trainDT = metrics.auc(fpr,tpr)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test),DTc.predict_proba(X_test)[:,1],pos_label=1)\n",
    "auc_testDT = metrics.auc(fpr,tpr)\n",
    "\n",
    "acc_DT = round(accuracy_trainDT*100,2)\n",
    "print('Accuracy of Train Data =',acc_DT,'%.')\n",
    "print('Accuracy of Test Data =',round(accuracy_testDT*100,2),'%.')\n",
    "print('AUC coeficient of Train Data =',round(auc_trainDT*100,2),'%.')\n",
    "print('AUC coeficient of Test Data =',round(auc_testDT*100,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix test for Decision Tree')\n",
    "display(confusion_matrix(Y_train, pred_trainDT))\n",
    "print('Cross Tabulation for test data in Decision Tree')\n",
    "display(pd.crosstab(Y_train,pd.Series(pred_trainDT),rownames=['ACTUAL'],colnames=['PRED']))\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Confusion Matrix test for Decision Tree')\n",
    "display(confusion_matrix(Y_test, pred_testDT))\n",
    "print('Cross Tabulation for test data in Decision Tree')\n",
    "display(pd.crosstab(Y_test,pd.Series(pred_testDT),rownames=['ACTUAL'],colnames=['PRED']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variance and Biased for Train Prediction')\n",
    "MSE(Y_train,pred_trainDT)\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Variance and Biased for Test Prediction')\n",
    "MSE_DT = MSE(Y_test,pred_testDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNc = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "KNNc.fit(X_train,Y_train)\n",
    "\n",
    "pred_trainKNN = KNNc.predict(X_train)\n",
    "pred_testKNN = KNNc.predict(X_test)\n",
    "\n",
    "accuracy_trainKNN = accuracy_score(pred_trainKNN,Y_train)\n",
    "accuracy_testKNN = accuracy_score(pred_testKNN,Y_test)\n",
    "\n",
    "#Auc = Area under Curve\n",
    "#Roc = Receiver Operating Characteristics\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train),KNNc.predict_proba(X_train)[:,1],pos_label=1)\n",
    "auc_trainKNN = metrics.auc(fpr,tpr)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test),KNNc.predict_proba(X_test)[:,1],pos_label=1)\n",
    "auc_testKNN = metrics.auc(fpr,tpr)\n",
    "\n",
    "acc_KNN = round(accuracy_trainKNN*100,2)\n",
    "print('Accuracy of Train Data =',acc_KNN,'%.')\n",
    "print('Accuracy of Test Data =',round(accuracy_testKNN*100,2),'%.')\n",
    "print('AUC coeficient of Train Data =',round(auc_trainKNN*100,2),'%.')\n",
    "print('AUC coeficient of Test Data =',round(auc_testKNN*100,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix test for k-Nearest Neighbors')\n",
    "display(confusion_matrix(Y_train, pred_trainKNN))\n",
    "print('Cross Tabulation for test data in k-Nearest Neighbors')\n",
    "display(pd.crosstab(Y_train,pd.Series(pred_trainKNN),rownames=['ACTUAL'],colnames=['PRED']))\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Confusion Matrix test for k-Nearest Neighbors')\n",
    "display(confusion_matrix(Y_test, pred_testKNN))\n",
    "print('Cross Tabulation for test data in k-Nearest Neighbors')\n",
    "display(pd.crosstab(Y_test,pd.Series(pred_testKNN),rownames=['ACTUAL'],colnames=['PRED']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variance and Biased for Train Prediction')\n",
    "MSE(Y_train,pred_trainKNN)\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Variance and Biased for Test Prediction')\n",
    "MSE_KNN = MSE(Y_test,pred_testKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 750, num = 10)]\n",
    "max_features = ['auto', 'log2']\n",
    "max_depth = [int(x) for x in np.linspace(3, 10, num = 1)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 250, cv = 2, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(X_train, Y_train)\n",
    "\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFHHc = RandomForestClassifier(**rf_random.best_params_)\n",
    "\n",
    "RFHHc.fit(X_train,Y_train)\n",
    "\n",
    "pred_trainRFH = RFHHc.predict(X_train)\n",
    "pred_testRFH = RFHHc.predict(X_test)\n",
    "\n",
    "accuracy_trainRFH = accuracy_score(pred_trainRFH,Y_train)\n",
    "accuracy_testRFH = accuracy_score(pred_testRFH,Y_test)\n",
    "\n",
    "#Auc = Area under Curve\n",
    "#Roc = Receiver Operating Characteristics\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train),RFHHc.predict_proba(X_train)[:,1],pos_label=1)\n",
    "auc_trainRFH = metrics.auc(fpr,tpr)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test),RFHHc.predict_proba(X_test)[:,1],pos_label=1)\n",
    "auc_testRFH = metrics.auc(fpr,tpr)\n",
    "\n",
    "acc_RFH = round(accuracy_trainRFH*100,2)\n",
    "print('Accuracy of Train Data =',acc_RFH,'%.')\n",
    "print('Accuracy of Test Data =',round(accuracy_testRFH*100,2),'%.')\n",
    "print('AUC coeficient of Train Data =',round(auc_trainRFH*100,2),'%.')\n",
    "print('AUC coeficient of Test Data =',round(auc_testRFH*100,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Confusion Matrix test for Random Forest Hypertuning')\n",
    "display(confusion_matrix(Y_train, pred_trainRFH))\n",
    "print('Cross Tabulation for test data in Random Forest Hypertuning')\n",
    "display(pd.crosstab(Y_train,pd.Series(pred_trainRFH),rownames=['ACTUAL'],colnames=['PRED']))\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Confusion Matrix test for Random Forest Hypertuning')\n",
    "display(confusion_matrix(Y_test, pred_testRFH))\n",
    "print('Cross Tabulation for test data in Random Forest Hypertuning')\n",
    "display(pd.crosstab(Y_test,pd.Series(pred_testRFH),rownames=['ACTUAL'],colnames=['PRED']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variance and Biased for Train Prediction')\n",
    "MSE(Y_train,pred_trainRFH)\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Variance and Biased for Test Prediction')\n",
    "MSE_RFH = MSE(Y_test,pred_testRFH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 150, num = 10)]\n",
    "max_features = ['auto', 'log2']\n",
    "max_depth = [int(x) for x in np.linspace(3, 10, num = 1)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "gf_tune = GridSearchCV(estimator = gb, param_grid = grid, cv = 2, verbose=2, n_jobs = -1)\n",
    "gf_tune.fit(X_train, Y_train)\n",
    "\n",
    "print(gf_tune.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GBHc = GradientBoostingClassifier(**gf_tune.best_params_)\n",
    "\n",
    "GBHc.fit(X_train,Y_train)\n",
    "pred_trainGBH = GBHc.predict(X_train)\n",
    "pred_testGBH = GBHc.predict(X_test)\n",
    "\n",
    "accuracy_trainGBH = accuracy_score(pred_trainGBH,Y_train)\n",
    "accuracy_testGBH = accuracy_score(pred_testGBH,Y_test)\n",
    "\n",
    "#Auc = Area under Curve\n",
    "#Roc = Receiver Operating Characteristics\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train),GBHc.predict_proba(X_train)[:,1],pos_label=1)\n",
    "auc_trainGBH = metrics.auc(fpr,tpr)\n",
    "\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test),GBHc.predict_proba(X_test)[:,1],pos_label=1)\n",
    "auc_testGBH = metrics.auc(fpr,tpr)\n",
    "\n",
    "acc_GBH = round(accuracy_trainGBH*100,2)\n",
    "print('Accuracy of Train Data =',acc_GBH,'%.')\n",
    "print('Accuracy of Test Data =',round(accuracy_testGBH*100,2),'%.')\n",
    "print('AUC coeficient of Train Data =',round(auc_trainGBH*100,2),'%.')\n",
    "print('AUC coeficient of Test Data =',round(auc_testGBH*100,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Confusion Matrix test for Gradient Boosting Hypertuning')\n",
    "display(confusion_matrix(Y_train, pred_trainGBH))\n",
    "print('Cross Tabulation for test data in Gradient Boosting Hypertuning')\n",
    "display(pd.crosstab(Y_train,pd.Series(pred_trainGBH),rownames=['ACTUAL'],colnames=['PRED']))\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Confusion Matrix test for Gradient Boosting Hypertuning')\n",
    "display(confusion_matrix(Y_test, pred_testGBH))\n",
    "print('Cross Tabulation for test data in Gradient Boosting Hypertuning')\n",
    "display(pd.crosstab(Y_test,pd.Series(pred_testGBH),rownames=['ACTUAL'],colnames=['PRED']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Variance and Biased for Train Prediction')\n",
    "MSE(Y_train,pred_trainGBH)\n",
    "\n",
    "print('_'*70+'\\n')\n",
    "\n",
    "print('Variance and Biased for Test Prediction')\n",
    "MSE_GBH = MSE(Y_test,pred_testGBH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Neural Network', \n",
    "              'Naive Bayes', 'Gradient Boosting', 'Suppport Vector Machine', \n",
    "              'Decision Tree', 'K-Nearest Neighbors', \n",
    "              'Random Forest - Hyper parameter tuning', \n",
    "              'Gradient Boosting - Hyper parameter tuning'],\n",
    "    'Score': [acc_log2, acc_RF, acc_NN, acc_NBy, acc_GB, acc_SVC, \n",
    "              acc_DT, acc_KNN, acc_RFH, acc_GBH],\n",
    "    'Variance' : [MSE_LOG[1], MSE_RF[1], MSE_NN[1], MSE_NBy[1], MSE_GB[1], \n",
    "                MSE_SVC[1], MSE_DT[1], MSE_KNN[1], MSE_RFH[1], MSE_GBH[1]],\n",
    "    'Biased' : [MSE_LOG[2], MSE_RF[2], MSE_NN[2], MSE_NBy[2], MSE_GB[2], \n",
    "                MSE_SVC[2], MSE_DT[2], MSE_KNN[2], MSE_RFH[2], MSE_GBH[2]]\n",
    "})\n",
    "display(models.sort_values(by='Score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def plots(agg1,target,type):\n",
    "\n",
    "    plt.figure(1,figsize=(20, 5))\n",
    "\n",
    "    plt.subplot(131)\n",
    "    plt.plot(agg1['DECILE'],agg1['ACTUAL'],label='Actual')\n",
    "    plt.plot(agg1['DECILE'],agg1['PRED'],label='Pred')\n",
    "    plt.xticks(range(10,110,10))\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.grid(True)\n",
    "    plt.title('Actual vs Predicted', fontsize=20)\n",
    "    plt.xlabel(\"Population %\",fontsize=15)\n",
    "    plt.ylabel(str(target) + \" \" + str(type) + \" %\",fontsize=15)\n",
    "\n",
    "    plt.subplot(132)\n",
    "    X = agg1['DECILE'].tolist()\n",
    "    X.append(0)\n",
    "    Y = agg1['DIST_TAR'].tolist()\n",
    "    Y.append(0)\n",
    "    plt.plot(sorted(X),sorted(Y))\n",
    "    plt.plot([0, 100], [0, 100],'r--')\n",
    "    plt.xticks(range(0,110,10))\n",
    "    plt.yticks(range(0,110,10))\n",
    "    plt.grid(True)\n",
    "    plt.title('Gains Chart', fontsize=20)\n",
    "    plt.xlabel(\"Population %\",fontsize=15)\n",
    "    plt.ylabel(str(target) + str(\" DISTRIBUTION\") + \" %\",fontsize=15)\n",
    "    plt.annotate(round(agg1[agg1['DECILE'] == 30].DIST_TAR.item(),2),xy=[30,30], \n",
    "            xytext=(25, agg1[agg1['DECILE'] == 30].DIST_TAR.item() + 5),fontsize = 13)\n",
    "    plt.annotate(round(agg1[agg1['DECILE'] == 50].DIST_TAR.item(),2),xy=[50,50], \n",
    "            xytext=(45, agg1[agg1['DECILE'] == 50].DIST_TAR.item() + 5),fontsize = 13)\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.plot(agg1['DECILE'],agg1['LIFT'])\n",
    "    plt.xticks(range(10,110,10))\n",
    "    plt.grid(True)\n",
    "    plt.title('Lift Chart', fontsize=20)\n",
    "    plt.xlabel(\"Population %\",fontsize=15)\n",
    "    plt.ylabel(\"Lift\",fontsize=15)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "def gains(data,decile_by,target,score):\n",
    "    inputs = list(decile_by)\n",
    "    inputs.extend((target,score))\n",
    "    decile = data[inputs]\n",
    "    grouped = decile.groupby(decile_by)\n",
    "    agg1 = pd.DataFrame({},index=[])\n",
    "    agg1['ACTUAL'] = grouped.mean()[target]*100\n",
    "    agg1['PRED'] = grouped.mean()[score]*100\n",
    "    agg1['DIST_TAR'] = grouped.sum()[target].cumsum()/grouped.sum()[target].sum()*100\n",
    "    agg1.index.name = 'DECILE'\n",
    "    agg1 = agg1.reset_index()\n",
    "    agg1['DECILE'] = agg1['DECILE']*10\n",
    "    agg1['LIFT'] = agg1['DIST_TAR']/agg1['DECILE']\n",
    "    plots(agg1,target,'Distribution')\n",
    "    \n",
    "def scoring(features,clf,target):\n",
    "    score = pd.DataFrame(clf.predict_proba(features)[:,1], columns = ['SCORE'])\n",
    "    score['DECILE'] = pd.qcut(score['SCORE'].rank(method = 'first'),10,labels=range(10,0,-1))\n",
    "    score['DECILE'] = score['DECILE'].astype(float)\n",
    "    score['TARGET'] = target\n",
    "    score['NONTARGET'] = 1 - target\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_train = scoring(X_train,RFHHc,Y_train)\n",
    "lift_train = pd.concat([X_train,scores_train],axis=1)\n",
    "gains(lift_train,['DECILE'],'TARGET','SCORE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test = scoring(X_test,RFHHc,Y_test)\n",
    "lift_test = pd.concat([X_test,scores_test],axis=1)\n",
    "gains(lift_test,['DECILE'],'TARGET','SCORE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
